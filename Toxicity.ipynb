{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9ea042",
   "metadata": {},
   "source": [
    "Installing and importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d220c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.10.0-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "     -------------------------------------- 455.9/455.9 MB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.48.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.0.7)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.32.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.11.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\naman agrawal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120bf5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a53b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832423df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3fcb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\nParzival418, you are trying to scare ThAtSo. How can you say that the comments of ThAtSo are \"\"insulting\"\"? ThAtSo is trying to suggest that there should be no original research in the Wikipedia. And, he is right. \"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[69]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "859da7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "6       1             1        1       0       1              0  \n",
       "12      1             0        0       0       0              0  \n",
       "16      1             0        0       0       0              0  \n",
       "42      1             0        1       0       1              1  \n",
       "43      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['toxic']==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdb591",
   "metadata": {},
   "source": [
    "Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "191975d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------\n",
      "absl-py                      1.0.0\n",
      "addict                       2.4.0\n",
      "aiofiles                     0.8.0\n",
      "anyio                        3.5.0\n",
      "argon2-cffi                  21.3.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "asgiref                      3.5.0\n",
      "asttokens                    2.0.5\n",
      "astunparse                   1.6.3\n",
      "attrs                        21.4.0\n",
      "autopep8                     1.7.0\n",
      "backcall                     0.2.0\n",
      "beautifulsoup4               4.10.0\n",
      "bleach                       4.1.0\n",
      "bokeh                        2.4.2\n",
      "cachetools                   5.2.0\n",
      "certifi                      2021.10.8\n",
      "cffi                         1.15.0\n",
      "charset-normalizer           2.0.12\n",
      "click                        8.1.2\n",
      "colorama                     0.4.4\n",
      "commonmark                   0.9.1\n",
      "cvzone                       1.5.6\n",
      "cycler                       0.11.0\n",
      "debugpy                      1.6.0\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "demjson3                     3.0.5\n",
      "docutils                     0.18.1\n",
      "entrypoints                  0.4\n",
      "et-xmlfile                   1.1.0\n",
      "executing                    0.8.3\n",
      "fastjsonschema               2.15.3\n",
      "Flask                        2.1.1\n",
      "flatbuffers                  2.0.7\n",
      "fonttools                    4.32.0\n",
      "gast                         0.4.0\n",
      "google-auth                  2.11.1\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.48.1\n",
      "h11                          0.12.0\n",
      "h5py                         3.7.0\n",
      "httpcore                     0.14.7\n",
      "httpx                        0.22.0\n",
      "idna                         3.3\n",
      "importlib-metadata           4.11.3\n",
      "ipykernel                    6.12.1\n",
      "ipython                      8.2.0\n",
      "ipython-genutils             0.2.0\n",
      "ipywidgets                   7.7.0\n",
      "itsdangerous                 2.1.2\n",
      "jedi                         0.18.1\n",
      "Jinja2                       3.1.1\n",
      "joblib                       1.2.0\n",
      "jsonschema                   4.4.0\n",
      "jupyter                      1.0.0\n",
      "jupyter-client               7.2.1\n",
      "jupyter-console              6.4.3\n",
      "jupyter-core                 4.9.2\n",
      "jupyterlab-pygments          0.1.2\n",
      "jupyterlab-widgets           1.1.0\n",
      "justpy                       0.2.3\n",
      "keras                        2.10.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "keyring                      23.5.0\n",
      "kiwisolver                   1.4.2\n",
      "libclang                     14.0.6\n",
      "Markdown                     3.4.1\n",
      "MarkupSafe                   2.1.1\n",
      "matplotlib                   3.5.1\n",
      "matplotlib-inline            0.1.3\n",
      "mediapipe                    0.8.10\n",
      "missingno                    0.5.1\n",
      "mistune                      0.8.4\n",
      "nbclient                     0.5.13\n",
      "nbconvert                    6.4.5\n",
      "nbformat                     5.3.0\n",
      "nest-asyncio                 1.5.5\n",
      "nltk                         3.7\n",
      "notebook                     6.4.10\n",
      "numpy                        1.22.3\n",
      "oauthlib                     3.2.1\n",
      "opencv-contrib-python        4.5.5.64\n",
      "opencv-python                4.5.5.64\n",
      "openpyxl                     3.0.9\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    21.3\n",
      "pandas                       1.4.2\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.3\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       9.1.0\n",
      "pip                          22.2.2\n",
      "pkginfo                      1.8.2\n",
      "plot                         0.6.5\n",
      "plotly                       5.10.0\n",
      "prometheus-client            0.13.1\n",
      "prompt-toolkit               3.0.29\n",
      "protobuf                     3.19.5\n",
      "psutil                       5.9.0\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.4.8\n",
      "pyasn1-modules               0.2.8\n",
      "pycodestyle                  2.9.1\n",
      "pycparser                    2.21\n",
      "Pygments                     2.11.2\n",
      "pynput                       1.7.6\n",
      "pyparsing                    3.0.7\n",
      "pyrsistent                   0.18.1\n",
      "python-dateutil              2.8.2\n",
      "pytz                         2021.1\n",
      "pywin32                      303\n",
      "pywin32-ctypes               0.2.0\n",
      "pywinpty                     2.0.5\n",
      "PyYAML                       6.0\n",
      "pyzmq                        22.3.0\n",
      "qtconsole                    5.3.0\n",
      "QtPy                         2.0.1\n",
      "readme-renderer              34.0\n",
      "regex                        2022.9.13\n",
      "requests                     2.27.1\n",
      "requests-oauthlib            1.3.1\n",
      "requests-toolbelt            0.9.1\n",
      "rfc3986                      1.5.0\n",
      "rich                         12.2.0\n",
      "rsa                          4.9\n",
      "scikit-learn                 1.1.2\n",
      "scipy                        1.9.1\n",
      "seaborn                      0.12.0\n",
      "Send2Trash                   1.8.0\n",
      "setuptools                   58.1.0\n",
      "six                          1.16.0\n",
      "sklearn                      0.0\n",
      "sniffio                      1.2.0\n",
      "soupsieve                    2.3.1\n",
      "stack-data                   0.2.0\n",
      "starlette                    0.19.0\n",
      "tenacity                     8.1.0\n",
      "tensorboard                  2.10.0\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.10.0\n",
      "tensorflow-estimator         2.10.0\n",
      "tensorflow-gpu               2.10.0\n",
      "tensorflow-io-gcs-filesystem 0.27.0\n",
      "termcolor                    2.0.1\n",
      "terminado                    0.13.3\n",
      "testpath                     0.6.0\n",
      "threadpoolctl                3.1.0\n",
      "toml                         0.10.2\n",
      "tornado                      6.1\n",
      "tqdm                         4.64.1\n",
      "traitlets                    5.1.1\n",
      "twine                        4.0.0\n",
      "typing                       3.7.4.3\n",
      "typing_extensions            4.1.1\n",
      "urllib3                      1.26.9\n",
      "uvicorn                      0.17.6\n",
      "wcwidth                      0.2.5\n",
      "webencodings                 0.5.1\n",
      "websockets                   10.2\n",
      "Werkzeug                     2.1.1\n",
      "wheel                        0.37.1\n",
      "widgetsnbextension           3.6.0\n",
      "wrapt                        1.14.1\n",
      "xlrd                         2.0.1\n",
      "zipp                         3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80e679ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e120b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextVectorization??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0ff73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['comment_text']\n",
    "y=df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aeebde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52bad9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f17fabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                            output_sequence_length=1800,\n",
    "                            output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea3f07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ad5a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text=vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f9516ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  643,    76,     2, ...,     0,     0,     0],\n",
       "       [    1,    54,  2506, ...,     0,     0,     0],\n",
       "       [  425,   440,    70, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32141,  7329,   383, ...,     0,     0,     0],\n",
       "       [    5,    12,   533, ...,     0,     0,     0],\n",
       "       [    5,     8,   130, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc66733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices((vectorized_text,y))\n",
    "dataset=dataset.cache()\n",
    "dataset=dataset.shuffle(160000)\n",
    "dataset=dataset.batch(16)\n",
    "dataset=dataset.prefetch(8) #help prevent bottelnecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ede629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y=dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27adf4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1800)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f23b684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0f8fe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6981"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(dataset)*.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a9e1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=dataset.take(int(len(dataset)*.7))\n",
    "val=dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))#validation partition\n",
    "test=dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e94873b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d97825f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "359ad406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2395,   305,     2, ...,     0,     0,     0],\n",
       "        [23545, 15361,    82, ...,     0,     0,     0],\n",
       "        [ 6839, 11188,  5424, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  175,    40,     8, ...,     0,     0,     0],\n",
       "        [  908,    11, 16449, ...,     0,     0,     0],\n",
       "        [  340,   340,     0, ...,     0,     0,     0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d898c7c1",
   "metadata": {},
   "source": [
    "Building the deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e4f3d",
   "metadata": {},
   "source": [
    "Create Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d6b961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca7e8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c307003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(MAX_FEATURES+1,32))#An extra one is to embedd the words that were beyond the range\n",
    "#LSTM Layer activation is tanh beacause tanh is required for gpu computation of LSTM\n",
    "\n",
    "#Bidirectional is required because hate is considered as toxic but like dont't hate is non-toxic so bidirectional is required to handle these kind of cases\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh'))) \n",
    "#3 dense layer for feautre extraction with an activation of relu\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#Final layer maps to the number of different outputs we have got using sigmoid activation it makes our output to be between 0 to 1\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "703bd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2b43e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 6, 32)             6400032   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,950,476\n",
      "Trainable params: 12,950,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ecf1c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'bidirectional/forward_lstm/lstm_cell_1/kernel:0', 'bidirectional/forward_lstm/lstm_cell_1/recurrent_kernel:0', 'bidirectional/forward_lstm/lstm_cell_1/bias:0', 'bidirectional/backward_lstm/lstm_cell_2/kernel:0', 'bidirectional/backward_lstm/lstm_cell_2/recurrent_kernel:0', 'bidirectional/backward_lstm/lstm_cell_2/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'bidirectional/forward_lstm/lstm_cell_1/kernel:0', 'bidirectional/forward_lstm/lstm_cell_1/recurrent_kernel:0', 'bidirectional/forward_lstm/lstm_cell_1/bias:0', 'bidirectional/backward_lstm/lstm_cell_2/kernel:0', 'bidirectional/backward_lstm/lstm_cell_2/recurrent_kernel:0', 'bidirectional/backward_lstm/lstm_cell_2/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "6981/6981 [==============================] - 1995s 285ms/step - loss: 0.1436 - val_loss: 0.1414\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train,epochs=1,validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909fe99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
